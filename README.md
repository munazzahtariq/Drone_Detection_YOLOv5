#  Drone Detection using YOLOv5

This project involves custom training a YOLOv5 model for drone detection using a publicly available dataset from Kaggle. It also includes a traditional OpenCV-based color segmentation technique (`drone_detection.py`) as an additional method.

---

##  Dataset

The dataset used is from Kaggle:  
ðŸ”— [Drone YOLO Detection](https://www.kaggle.com/datasets/sshikamaru/drone-yolo-detection)

The dataset includes drone images with annotated bounding boxes in YOLO format. I split the dataset into training and validation sets using `SPLIT.py`.

Iâ€™ve added a Word file (`Drone_Detection_Results.docx`) containing:
- A screenshot of the original Kaggle dataset page
- Dataset folder structure after splitting
- Sample detection results from the trained model

Due to licensing, the dataset itself is **not included**.

---

##  YOLOv5 Training & Detection

I used the official YOLOv5 repository from Ultralytics:  
ðŸ”— [YOLOv5 GitHub](https://github.com/ultralytics/yolov5)

### Files Used:
- `train.py`: To train the model using custom drone data
- `detect.py`: To run detections after training

**Note**: YOLOv5 does not include "drone" as a default class â€” I custom-trained it with one class: `drone`.

The dataset follows YOLO format: each image must have a corresponding `.txt` label file with bounding box coordinates.

---

##  data.yaml

This file defines:
- Paths to the training and validation image folders
- Number of classes (1)
- Name of the class (`drone`)

---

##  Supporting Scripts

- `CORRUPT.py`: Removes corrupted or unreadable image/label files before training.
- `SPLIT.py`: Splits the dataset into training (80%) and validation (20%) sets.
- `drone_detection.py`: Uses OpenCV techniques (HSV masking, blurring, contouring) to detect drones in static images based on color. This method is independent of YOLO and works best for detecting visually distinct drones (e.g., black-colored drones).

---

##  Training Results

The `results.csv` file logs:
- Training & validation loss
- mAP@0.5 and mAP@0.5:0.95 values across epochs  
*(auto-generated by YOLOv5)*

Iâ€™ve also shared detection result images in the `.docx` file.

---

##  Model Training Command

## bash (VISUAL STUDIO CODE)
python train.py --img 416 --batch 4 --epochs 50 --data data.yaml --cfg models/yolov5n.yaml --weights yolov5n.pt --name drone_yolov5n 

# for image detection
python detect.py --weights runs/train/drone_yolov5n/weights/last.pt --img 640 --conf 0.25 --source images/val --name drone_yolov5n_detect

#for video detection
python detect.py --weights runs/train/drone_yolov5n/weights/best.pt --source drone_video.mp4

#for webcam detection
python detect.py --weights runs/train/drone_yolov5n/weights/best.pt --source 0

## Notes:

You can change --img, --batch, --epochs based on your system.

--data: Path to your data.yaml file.

--weights: Use a base model like yolov5n.pt or yolov5s.pt.

--name: Name of the training run.
#
